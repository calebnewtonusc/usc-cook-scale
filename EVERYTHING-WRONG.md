# ğŸ”¥ EVERYTHING WRONG WITH THIS PROJECT ğŸ”¥

**Date:** February 6, 2026
**Status:** CRITICAL FAILURES ACROSS THE BOARD

---

## ğŸš¨ **TIER 1: CATASTROPHIC FAILURES** (App is Broken)

### 1. **Professor Matching: 100% Failure Rate**
- âŒ **Every professor returns `null`**
- âŒ RMP GraphQL API is being called but finding NO results
- âŒ Name format issue: "Slocum, Carter" might not match RMP "Carter Slocum"
- âŒ LLM verification is never reached because search returns empty
- âŒ User sees "No RateMyProfessors data available" for EVERY class

**Impact:** The entire "verified professor matching" feature doesn't work AT ALL

### 2. **Course Difficulty Analysis: Immediate Fallback**
- âŒ **EVERY class gets fallback score** (35 or 60 based on basic regex)
- âŒ LLM course analysis is failing/timing out/returning unparseable JSON
- âŒ Says "Fallback analysis based on course code" for everything
- âŒ No actual intelligent analysis happening

**Impact:** No difference from a simple if(courseName.includes('CSCI')) return 60

### 3. **RMP Review Quotes: Zero Results**
- âŒ **No reviews extracted for ANY professor**
- âŒ Even if professor is found, review fetch fails
- âŒ GraphQL query might be malformed or blocked
- âŒ User sees empty quotes section on EVERY class

**Impact:** Promised "real student quotes" - delivers nothing

### 4. **Reddit Integration: Completely Broken**
- âŒ **No Reddit quotes for ANY class**
- âŒ Reddit API might be rate limiting
- âŒ Search query might be malformed
- âŒ Posts might exist but not being fetched

**Impact:** Another promised feature that doesn't work

### 5. **Overall Score: Worthless**
- âŒ **Just averages the fallback scores**
- âŒ Says "Calculated as average of individual class scores"
- âŒ No LLM workload synergy analysis happening
- âŒ **18-unit semester = "32/100 Lightly Toasted"** (clearly wrong!)

**Impact:** Students can't trust the main score

### 6. **Survival Tips: Generic Garbage**
- âŒ **Same 3 tips for EVERY class:**
  - "Maintain consistent effort"
  - "Review concepts regularly"
  - "Use this class to balance harder courses"
- âŒ No personalization whatsoever
- âŒ LLM generation failing, falling back to hardcoded tips

**Impact:** Users think "Why did I waste time uploading my schedule?"

---

## ğŸ”´ **TIER 2: MAJOR BUGS** (Broken Promises)

### 7. **LLM Calls Failing Silently**
- âŒ No error messages shown to user
- âŒ Try-catch blocks return empty/default data
- âŒ User has no idea everything is broken
- âŒ Logs say "[V2]" but there's no V2 intelligence happening

### 8. **Timeout Issues**
- âŒ 60-second timeout might not be enough for 6 classes
- âŒ Each class makes 6+ LLM calls (professor match, difficulty, impact, tips, insights, overall)
- âŒ **6 classes Ã— 6 LLM calls = 36 API calls in 60 seconds** = guaranteed timeouts
- âŒ No batching, no parallelization optimization

### 9. **API Rate Limiting**
- âŒ RMP GraphQL might be blocking requests
- âŒ Reddit JSON API might be rate limiting
- âŒ Anthropic API might hit rate limits with 36 calls
- âŒ No retry logic, no exponential backoff

### 10. **JSON Parsing Errors**
- âŒ LLM returns markdown instead of JSON
- âŒ LLM returns JSON with extra text before/after
- âŒ JSON.parse() fails, crashes to fallback
- âŒ No validation of LLM responses

### 11. **Professor Name Format Mismatch**
- âŒ WebReg gives "Slocum, Carter"
- âŒ RMP expects "Carter Slocum" or "C. Slocum"
- âŒ Search fails because format doesn't match
- âŒ LLM verification never runs because search returns empty

### 12. **Missing Error Handling**
- âŒ User never sees actual errors
- âŒ "Analysis failed - using default score" is hidden from user
- âŒ Silently fails and shows garbage results
- âŒ User thinks it worked but got bad data

---

## ğŸŸ¡ **TIER 3: UX/UI PROBLEMS** (Poor User Experience)

### 13. **Loading Time: Too Long**
- âŒ Takes 30+ seconds per class
- âŒ 6 classes = 3+ minutes of waiting
- âŒ No progress indicator showing which class is being analyzed
- âŒ User thinks app froze

### 14. **No Transparency**
- âŒ Doesn't tell user when RMP professor not found
- âŒ Doesn't explain why there are no quotes
- âŒ Doesn't show confidence score for professor match
- âŒ User can't tell if data is real or fallback

### 15. **Results Look Fake**
- âŒ All scores suspiciously similar (35, 35, 35, 35...)
- âŒ AI insights are vague and generic
- âŒ No actual data differentiation between classes
- âŒ Students will immediately recognize this as BS

### 16. **No Source Attribution**
- âŒ Quotes (when they work) don't link to actual review
- âŒ Can't verify if AI insights are accurate
- âŒ No way to check if RMP data is current
- âŒ Feels untrustworthy

### 17. **Color Scheme Issues**
- âŒ All classes show same color (green for 35/100)
- âŒ No visual differentiation
- âŒ Border color logic exists but all scores identical so pointless

### 18. **Mobile UI Not Optimized**
- âŒ Probably terrible on phone
- âŒ Long class cards
- âŒ No responsive testing done

---

## ğŸŸ¢ **TIER 4: DATA QUALITY ISSUES**

### 19. **Incorrect Course Classifications**
- âŒ Regex matching "CSCI" â†’ STEM is too simplistic
- âŒ MATH-118 (stats) vs MATH-226 (calc) both treated same
- âŒ GE courses misclassified
- âŒ Doesn't account for course level (100 vs 400)

### 20. **Professor Ratings Unreliable**
- âŒ When found, takes FIRST result without verification
- âŒ Might be wrong professor with same name
- âŒ No confidence threshold
- âŒ Could be professor from different university

### 21. **Outdated Data**
- âŒ RMP ratings could be from 5 years ago
- âŒ Professor might have changed teaching style
- âŒ No weighting for recent reviews
- âŒ No indication of data freshness

### 22. **Missing Data Not Handled Well**
- âŒ New professors have no data â†’ shows as "35/100"
- âŒ Graduate TAs not in RMP â†’ ignored
- âŒ Visiting professors â†’ no data
- âŒ Should explain "No data available" vs "Easy class"

---

## ğŸ”µ **TIER 5: ALGORITHMIC PROBLEMS**

### 23. **Unit Multiplier is Weird**
- âŒ 2-unit guitar class gets `35 Ã— 0.5 = 17.5`
- âŒ Makes sense mathematically but feels arbitrary
- âŒ Doesn't account for time-intensive 2-unit labs
- âŒ Unit count â‰  difficulty perfectly

### 24. **STEM Bias**
- âŒ Auto-assumes all STEM = harder
- âŒ CSCI-180 (intro) scores same as CSCI-104 (notorious)
- âŒ Some humanities courses (ancient languages) are brutal
- âŒ Oversimplified binary classification

### 25. **Professor Impact Formula Unclear**
- âŒ LLM decides multiplier but logic is opaque
- âŒ "Hard but fair" (high difficulty, high quality) handled how?
- âŒ Students can't predict how their prof affects score
- âŒ Feels arbitrary

### 26. **Overall Score Doesn't Account For:**
- âŒ Time conflicts (classes at same time = impossible)
- âŒ Location conflicts (back-to-back classes across campus)
- âŒ Exam schedules (3 midterms same week)
- âŒ Prerequisites (advanced course without background)
- âŒ Workload synergy (3 STEM classes = compound difficulty)

### 27. **Verbal Labels Misleading**
- âŒ "Lightly Toasted" for 32/100 seems good
- âŒ But 18 units with those classes is actually hard!
- âŒ Labels don't match student reality
- âŒ Needs recalibration based on real feedback

---

## ğŸŸ£ **TIER 6: TECHNICAL DEBT**

### 28. **Code Duplication**
- âŒ Old v1 endpoint still exists
- âŒ ClassBreakdown and ClassBreakdownV2 both in codebase
- âŒ CookScoreDisplay and CookScoreDisplayV2
- âŒ Confusing which is actually being used

### 29. **No Tests**
- âŒ Zero unit tests
- âŒ Zero integration tests
- âŒ No test coverage for LLM responses
- âŒ Relying on manual testing = bugs slip through

### 30. **No Logging/Monitoring**
- âŒ Can't debug production failures
- âŒ Don't know when RMP API goes down
- âŒ Don't know LLM failure rate
- âŒ No Sentry/error tracking

### 31. **Hardcoded Values Everywhere**
- âŒ USC School ID hardcoded
- âŒ Timeout values hardcoded
- âŒ Base difficulty scores hardcoded
- âŒ Should be in config file

### 32. **No Caching**
- âŒ Same professor fetched multiple times
- âŒ Same Reddit searches repeated
- âŒ LLM calls not cached
- âŒ Wasting time and money

### 33. **Environment Variable Confusion**
- âŒ VITE_API_URL might not be set
- âŒ Anthropic API key might expire
- âŒ No validation on startup
- âŒ Silent failures if env vars missing

---

## ğŸŸ¤ **TIER 7: MISSING FEATURES**

### 34. **No User Accounts**
- âŒ Can't save schedules
- âŒ Can't compare semesters
- âŒ Can't share results with friends
- âŒ Have to re-enter every time

### 35. **No Schedule Comparison**
- âŒ Can't compare "should I take Smith or Jones?"
- âŒ Can't see "what if I drop this class?"
- âŒ No A/B testing schedules

### 36. **No PDF Upload Persistence**
- âŒ Upload PDF, analyze, then lose it
- âŒ Want to adjust? Re-upload
- âŒ Annoying UX

### 37. **No Export/Share Functionality**
- âŒ Can't export to PDF with results
- âŒ Can't share link with friends
- âŒ Print function is basic browser print
- âŒ No social sharing

### 38. **No Historical Data**
- âŒ Doesn't track "was this accurate?"
- âŒ Can't improve algorithm based on feedback
- âŒ No community validation

---

## âš« **TIER 8: DEPLOYMENT ISSUES**

### 39. **Build Failures**
- âŒ TypeScript errors slip through
- âŒ Had to fix CookScoreDisplay vs V2 issue
- âŒ No pre-commit hooks
- âŒ Deploy breaks production

### 40. **No Staging Environment**
- âŒ Testing on production
- âŒ Users see broken features
- âŒ Can't test safely

### 41. **Vercel Function Timeout**
- âŒ 60-second limit might not be enough
- âŒ Complex schedules will timeout
- âŒ No background job processing

### 42. **CORS Issues (Potential)**
- âŒ Might break on some browsers
- âŒ Preflight requests might fail
- âŒ Headers set multiple places (redundant)

---

## ğŸ’€ **TIER 9: FATAL FLAWS** (Existential Problems)

### 43. **Value Proposition Unclear**
- âŒ If it just shows "35" for everything, why use it?
- âŒ Easier to just Google "CSCI-104 Reddit USC"
- âŒ Not providing value over manual research
- âŒ Students won't recommend it

### 44. **Trust Issues**
- âŒ Results don't match student experience
- âŒ "This class is hard but it says 35/100?"
- âŒ Once trust is lost, won't be used
- âŒ Critical for adoption

### 45. **Not USC-Specific Enough**
- âŒ Doesn't use USC course catalog
- âŒ Doesn't know USC-specific course difficulty
- âŒ Doesn't account for USC culture (CSCI-104 is legendary hard at USC)
- âŒ Generic tool trying to be specific

### 46. **Doesn't Account for Student Differences**
- âŒ CS major vs non-major taking CSCI-101 = different difficulty
- âŒ Math background affects MATH-226 difficulty
- âŒ Everyone gets same score regardless of background
- âŒ Not personalized

### 47. **Legal/Ethical Issues**
- âŒ Scraping RMP might violate terms of service
- âŒ Reddit scraping might have rate limits/TOS
- âŒ Using USC name without permission?
- âŒ Liability if student trusts bad recommendation?

### 48. **Scalability**
- âŒ Can't handle 1000 concurrent users
- âŒ LLM costs scale linearly with usage
- âŒ No business model to sustain
- âŒ Will run out of free Anthropic credits

---

## ğŸ“Š **SUMMARY OF CRITICAL FAILURES**

**What Actually Works:**
1. âœ… PDF parsing (from previous work)
2. âœ… Frontend displays data (even if it's garbage)
3. âœ… Deployment pipeline works
4. âœ… UI looks decent (just showing bad data)

**What is COMPLETELY BROKEN:**
1. âŒ Professor matching (0% success rate)
2. âŒ RMP review quotes (0 quotes extracted)
3. âŒ Reddit discussions (0 found)
4. âŒ Course difficulty analysis (100% fallback)
5. âŒ Personalized survival tips (100% generic)
6. âŒ Overall score intelligence (just an average)

**Percentage of V2 Features Working:**
- **~15%** (basic functionality works, all "intelligent" features broken)

**User Experience Rating:**
- **2/10** (Worse than if we just showed RMP links and said "research yourself")

---

## ğŸ¯ **THE FUNDAMENTAL PROBLEM**

The entire V2 algorithm is built on:
1. LLM calls that are failing
2. API integrations that don't work
3. Fallbacks that make it seem like it works

**It's a house of cards that LOOKS impressive but DOES NOTHING.**

Students will try it once, see generic results, and never come back.

---

## ğŸš€ **WHAT NEEDS TO HAPPEN IMMEDIATELY**

**Do This Today:**
1. Fix RMP professor search (handle name formats)
2. Make LLM calls more robust (handle errors, parse JSON better)
3. Add retry logic for API failures
4. Show user when data is missing vs when using fallback
5. Test with REAL schedules and verify accuracy

**Do This Week:**
6. Implement caching to speed up repeat queries
7. Add progress indicators for long analysis
8. Improve error messages
9. Add source links to verify data
10. Get real student feedback and iterate

**Do This Month:**
11. Build test suite
12. Add monitoring/logging
13. Optimize for speed
14. Add user accounts
15. Launch marketing push (ONLY when it actually works)

---

**Bottom Line:** This is an AMAZING idea executed with BROKEN implementation. Fix the core data pipeline before adding features.

**The promise:** "AI-powered intelligent analysis with real student quotes"
**The reality:** "Regex-based fallback scores with no data"

**Students aren't stupid - they'll notice immediately.**
